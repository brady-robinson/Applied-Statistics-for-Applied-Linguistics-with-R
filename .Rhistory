c2_subset <- subset(manova_data, School == "online")
c2_subset
c3_subset <- subset(manova_data, School == "hybrid")
c3_subset
shapiro.test(x = c1_subset$Speaking_Score)
shapiro.test(x = c1_subset$Writing_Score)
shapiro.test(x = c2_subset$Speaking_Score)
shapiro.test(x = c2_subset$Writing_Score)
shapiro.test(x = c3_subset$Speaking_Score)
shapiro.test(x = c3_subset$Writing_Score)
dim(c1_subset)
dim(c2_subset)
dim(c3_subset)
output_boxm <- boxM(manova_data[,2:3], manova_data[,1])
summary(output_boxm)
corr_output <- cor.test(manova_data$Speaking_Score, manova_data$Writing_Score, method = "pearson")
corr_output
ggplot(c1_subset, aes(Speaking_Score, Writing_Score)) + geom_point()
ggplot(c2_subset, aes(Speaking_Score, Writing_Score)) + geom_point()
ggplot(c3_subset, aes(Speaking_Score, Writing_Score)) + geom_point()
cols_for_maha <- c("Speaking_Score", "Writing_Score")
data_for_maha <- manova_data[cols_for_maha]
data_for_maha
sort(maha_dist(data_for_maha))
?sort
means <- colMeans(data_for_maha)
covx <- cov(data_for_maha)
maha_values <- mahalanobis(data_for_maha,means, covx)
sort(maha_values)
output_boxm <- boxM(manova_data[,2:3], manova_data[,1])
summary(output_boxm)
# Levene's test for homogeneirty of variance
leveneTest(manova_data$Speaking_Score, manova_data$School, center = mean)
leveneTest(manova_data$Writing_Score, manova_data$School, center = mean)
by(manova_data$Speaking_Score, manova_data$School, stat.desc, basic=F)
by(manova_data$Writing_Score, manova_data$School, stat.desc, basic=F)
# Running the MANOVA test
residuals_manova <- manova(cbind(Speaking_Score, Writing_Score) ~ School,
data = manova_data)
summary(residuals_manova, test="Wilks")
summary.aov(residuals_manova)
#install.packages("lsr")
library(lsr)
effect_size_speaking <- etaSquared(speaking_model)
speaking_model <- lm(Speaking_Score ~ School, data=manova_data)
writing_model <- lm(Writing_Score ~ School, data=manova_data)
effect_size_speaking <- etaSquared(speaking_model)
effect_size_writing <- etaSquared(writing_model)
effect_size_speaking
effect_size_writing
effect_size_speaking[,1]
effect_size_writing[,1]
tot_eff_size <- (eff_size_1 + eff_size_2)/2
tot_eff_size
tot_eff_size <- ((eff_size_1 + eff_size_2)/2)
eff_size_1 <- effect_size_speaking[,1]
eff_size_2 <- effect_size_writing[,1]
tot_eff_size <- ((eff_size_1 + eff_size_2)/2)
tot_eff_size
summary.aov(manova_model)
manova_model <- manova(bound_outcomes ~ School, data = manova_data)
summary(manova_model, intercept = TRUE) # default Pillai test
summary(manova_model, intercept = TRUE, test = "Wilks")
summary.aov(manova_model)
bound_outcomes <- cbind(manova_data$Speaking_Score, manova_data$Writing_Score)
manova_model <- manova(bound_outcomes ~ School, data = manova_data)
summary(manova_model, intercept = TRUE) # default Pillai test
summary(manova_model, intercept = TRUE, test = "Wilks")
summary.aov(manova_model)
eff_size_1 <- effect_size_speaking[,1]
eff_size_2 <- effect_size_writing[,1]
eff_size_1
eff_size_2
# install.packages("multcomp")
library(multcomp)
post_hocs_speaking <- glht(speaking_model, linfct = mcp(School = "Tukey"))
post_hocs_writing <- glht(writing_model, linfct = mcp(School = "Tukey"))
summary(post_hocs_speaking)
summary(post_hocs_writing)
eff_size_speaking <- effect_size_speaking[,1]
eff_size_writing <- effect_size_writing[,1]
eff_size_writing
eff_size_speaking
eff_size_writing
effect_size_manova <- etaSquared(manova_model)
library(gdata)
library(ggplot2)
library(dplyr)
library(car)
regression_data <- read.xls(file.choose())
regression_data
regression_data
regression_data <- read.xls(file.choose())
regression_data
regression_model <- lm(speaking_score ~ study_time + age + anxiety_level +
study_time + lived_eng, data = regression_data)
summary(regression_model)
durbinWatsonTest(regression_model)
influence(regression_model)
outlierTest(regression_model)
predicted_values <- predict(regression_model)
residual_values <- regression_model$residuals
ggplot(regression_model, aes(predicted_values, residual_values)) + geom_point()
ggplot(regression_model, aes(regression_model$residuals)) + geom_histogram()
qqPlot(regression_model$residuals)
install.packages("MASS")
install.packages("MASS")
library(MASS)
sresid <- studres(regression_model)
sresid
predicted_values <- predict(regression_model)
predicted_values
regression_data
ggplot(aes(sresid, predicted_values)) + geom_point()
ggplot(data = FALSE, aes(sresid, predicted_values)) + geom_point()
frame_for_plot <- cbind(sresid, predicted_values)
ggplot(frame_for_plot, aes(sresid, predicted_values)) + geom_point()
frame_for_plot <- as.data.frame(cbind(sresid, predicted_values))
ggplot(frame_for_plot, aes(sresid, predicted_values)) + geom_point()
frame_for_plot
sresid
predicted_values
avPlot(regression_model)
regression_data
avPlot(regression_model, variable = "anxiety_level")
avPlot(regression_model, variable = "age")
avPlot(regression_model, variable = "anxiety_level")
avPlot(regression_model, variable = "study_time")
avPlot(regression_model, variable = "lived_eng")
avPlot(regression_model, variable = "age")
avPlot(regression_model, variable = "anxiety_level")
avPlot(regression_model, variable = "study_time")
avPlot(regression_model, variable = "lived_eng")
ggplot(frame_for_plot, aes(sresid, predicted_values)) + geom_point()
regression_model
sumary(regression_model)
summary(regression_model)
vif(regression_model)
?outlierTest
outlierTest(regression_model)
summary(regression_model)
install.packages("lm.beta")
library(lm.beta)
coef.lm.beta(regression_model, standardized = FALSE)
coef.lm.beta(regression_model, standardized = TRUE)
coef.lm.beta(regression_model)
coef.lm.beta(regression_model, standardized = TRUE)
?coef
coef(regression_model)
scaled_model <- lm(scale(speaking_score) ~ scale(study_time) + scale(age) + scale(anxiety_level) +
scale(study_time) + scale(lived_eng), data = regression_data)
summary(scaled_model$coefficients)
summary(scaled_model)
coef(scaled_model)
regression_data
regression_data
regression_data <- read.xls(file.choose())
regression_data
regression_data <- read.xls(file.choose())
install.packages("MASS")
# install.packages("MASS")
library(gdata)
library(ggplot2)
library(dplyr)
library(car)
library(MASS)
regression_data <- read.xls(file.choose())
regression_data <- read.xls(file.choose())
regression_data
regression_model_1 <- lm(speaking_score ~ age + lived_eng, data = regression_data)
regression_model_2 <- lm(speaking_score ~ age + lived_eng + anxiety_level, data = regression_data)
regression_model_3 <- lm(speaking_score ~ age + lived_eng + anxiety_level + study_time, data = regression_data)
summary(regression_model_1)
summary(regression_model_2)
summary(regression_model_3)
str(regression_model_1)
summary(regression_model_1)
summary(regression_model_2)
summary(regression_model_3)
anova(regression_model_1, regression_model_2, regression_model_3)
scaled_model_1 <- lm(scale(speaking_score) ~ scale(age) + scale(lived_eng), data = regression_data)
scaled_model_2 <- lm(scale(speaking_score) ~ scale(age) + scale(anxiety_level) +
+ scale(lived_eng), data = regression_data)
scaled_model_3 <- lm(scale(speaking_score) ~ scale(study_time) + scale(age) + scale(anxiety_level) +
+ scale(lived_eng), data = regression_data)
coef(scaled_model_1)
coef(scaled_model_2)
coef(scaled_model_3)
# install.packages("MASS")
library(gdata)
library(ggplot2)
library(dplyr)
library(car)
library(MASS)
regression_data <- read.xls(file.choose())
regression_data
regression_model <- glm(pass_fail ~ speaking_score + age + lived_eng + study_time, data = regression_data)
summary(regression_model)
regression_model <- glm(pass_fail ~ speaking_score + age + lived_eng + study_time, data = regression_data, family = binomial)
summary(regression_model)
probabilities <- predict(regression_model, type = "response")
probabilities
predictions <- ifelse(probabilities > 0.5, "pass", "fail")
table(predictions, regression_data$pass_fail)
mean(predictions ==  Direction)
mean(predictions ==  regression_data$pass_fail)
percent_correct_pass = (16/(16+19))*100
percent_correct_pass
percent_correct_fail = (55/(55+10))*100
percent_correct_fail
percent_correct_total = (percent_correct_fail + percent_correct_pass)/2
percent_correct_total
percent_correct_total = (percent_correct_fail*65 + percent_correct_pass*35)/2
percent_correct_total
prop_correct_pass = 16/(16+19)
prop_correct_fail = 55/(55+10)
percent_correct_total = prop_correct_fail*65 + prop_correct_pass*35
percent_correct_total
# install.packages("MASS")
install.packages("rcompanion")
library(rcompanion)
nagelkerke(regression_model)
install.packages("rcompanion")
library(rcompanion)
nagelkerke(regression_model)
install.packages("ResourceSelection")
library(ResourceSelection)
hoslem.test(regression_data$pass_fail,fitted(regression_model))
summary(regression_model)
install.packages("survey")
library(survey)
?regTermTest
regTermTest(regression_model, "pass_fail")
regTermTest(fitted(regression_model), "pass_fail")
regression_model
regression_data
regTermTest(regression_model, regression_data$pass_fail)
regTermTest(regression_model, "pass_fail")
regTermTest(regression_model, ~age+study_time+lived_eng+speaking_score)
regTermTest(regression_model, ~age)
regTermTest(regression_model, ~age)
regTermTest(regression_model, ~study_time)
regTermTest(regression_model, ~lived_eng)
regTermTest(regression_model, ~speaking_score)
summary(regression_model)
exp(coef(regression_model))
exp(confint(regression_model))
exp(confint.default(regression_model))
test_data <- read.xls(file.choose())
library(gdata)
test_data <- read.xls(file.choose())
test_data
?summary
summary(test_data$total_multiple_choice)
skewness(test_data$total_multiple_choice)
install.packages("time")
install.packages("fBasics")
library(fBasics)
basicsStats(test_data$total_multiple_choice)
basicStats(test_data$total_multiple_choice)
basicStats(test_data$speaking_average)
library(DescTools)
Mode(test_data$total_multiple_choice)
?DescTools
basicStats(test_data$speaking_average)
install.packages("timeDate")
install.packages("timeDate")
library(timeDate)
skewness(test_data$total_multiple_choice)
basicStats(test_data$total_multiple_choice)
kurtosis(test_data$total_multiple_choice)
?fBasics
?DescTools
basicStats(test_data$total_multiple_choice)
install.packages("moments")
library(moments)
?moments
?moments
kurtosis(test_data$total_multiple_choice)
skewness(test_data$total_multiple_choice)
kurtosis(test_data$speaking_average)
skewness(test_data$speaking_average)
install.packages("e1071")
library(e1071)
library(e1071)
kurtosis(test_data$speaking_average)
skewness(test_data$speaking_average)
skewness(test_data$total_multiple_choice)
kurtosis(test_data$total_multiple_choice)
skewness(test_data$total_multiple_choice, type = 2)
kurtosis(test_data$total_multiple_choice, type = 2)
kurtosis(test_data$speaking_average, type = 2)
skewness(test_data$speaking_average, type = 2)
?histogram
?hist
hist(test_data$total_multiple_choice)
?hist
hist(test_data$total_multiple_choice, breaks = 6)
hist(test_data$total_multiple_choice, breaks = 6, main = "Histogram of Total Multiple Choice Scores")
hist(test_data$total_multiple_choice, breaks = 6, main = "Histogram of Total Multiple Choice Scores",
xlab = "Number Correct", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 6, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$total_multiple_choice, breaks = 6, main = "Histogram of Total Multiple Choice Scores",
xlab = "Number Correct", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 6, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$total_multiple_choice, breaks = 6, main = "Histogram of Total Multiple Choice Scores",
xlab = "Number Correct", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 5, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 6, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 4, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 4, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 3, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 4, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 7, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
hist(test_data$speaking_average, breaks = 6, main = "Histogram of Average Speaking Scores",
xlab = "Speaking Score", ylab = "Frequency")
#install.packages("fBasics")
#install.packages("moments")
#install.packages("e1071")
install.packages("psych")
test_data <- read.xls(file.choose())
test_data
test_data[,5:19]
alpha(test_data[,5:19])
#install.packages("fBasics")
#install.packages("moments")
#install.packages("e1071")
install.packages("psych")
library(psych)
alpha(test_data[,5:19])
?alpha
warnings()
alpha(test_data[,5:19], delete = FALSE)
test_data
alpha(test_data[,5:19], delete = FALSE, warnings = FALSE)
alpha(test_data[,5:19])
install.packages("psy")
library(psy)
cronbach(test_data[,5:19])
CronbachAlpha(test_data[,5:19])
?DescTools
basicStats(test_data[,5:19])
basicStats(test_data$total_multiple_choice)
basicStats(test_data$total_multiple_choice)[5,]
st_dev <- basicStats(test_data$total_multiple_choice)[14,]
st_dev <- basicStats(test_data$total_multiple_choice)[14,]
st_dev
cron_alpha <- CronbachAlpha(test_data[,5:19])
cron_alpha
# standard_error_measurement = Standard_deviation*sqrt(1) - Cronbach's_alpha
standard_error_measurement = st_dev*sqrt(1) - cron_alpha
standard_error_measurement
# standard_error_measurement = Standard_deviation*sqrt(1) - Cronbach's_alpha
standard_error_measurement = st_dev*sqrt(1 - cron_alpha)
standard_error_measurement
test_data <- read.xls(file.choose())
library(gdata)
library(fBasics)
library(DescTools)
test_data <- read.xls(file.choose())
test_data
install.packages("itemanalysis")
library(itemanalysis)
?itemanalysis
itemanalysis1(test_data[,5:14])
itemanalysis1(test_data[,5:14], key = c(1), options = c(0,1))
itemanalysis1(test_data[,5:14], key = c(0, 1), options = c(0,1))
itemanalysis1(test_data[,5:19], key = c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1),
options = c(0,1), ngroup = 15, correction = FALSE)
install.packages("sjmisc")
library(sjmisc)
reliab_test(test_data[,5:19)]
reliab_test(test_data[,5:19])
?sjmiss
?sjmisc
?reliab_test
reliab_test(test_data[,5:19])
install.packages("DeducerAlpha")
install.packages("sjstats")
library(sjstats)
reliab_test(test_data[,5:19])
?reliab_test
?sjstats
library(psych)
?psych
alpha(test_data[,5:19])
?alpha
alpha.ci(test_data[,5:19])
alpha(test_data[,5:19], delete = FALSE)
alpha(test_data[,5:19], na.rm = FALSE, delete = FALSE)
item_facility <- colMeans(test_data[,5:19], na.rm=TRUE)
item_facility
install.packages("ItemShinyAnalysis")
item_facility <- colMeans(test_data[,5:19], na.rm=TRUE)
item_facility
alpha(test_data[,5:19])
install.packages("CTT")
library(CTT)
?CTT
itemAnalysis(test_data[,5:19])
lf6 <- c("A", "A", "B", "B")
lf6 <- c("A", "A", "B", "B")
mm14 <- c("A", "C", "C", "C")
items <- cbind(lf6, mm14)
items
distractorAnalysis(items = test_items, key = c("B","C"))
test_items <- cbind(lf6, mm14)
distractorAnalysis(items = test_items, key = c("B","C"))
lf6 <- c("A", "A", "B", "B")
mm14 <- c("A", "C", "C", "C")
test_items <- cbind(lf6, mm14)
distractorAnalysis(items = lf6, key = c("B"))
distractorAnalysis(items = lf6, key = "B")
lf6 <- c("A", "A", "B", "B")
mm14 <- c("A", "C", "C", "C")
test_items <- cbind(lf6, mm14)
distractorAnalysis(items = lf6, key = "B")
distractorAnalysis(items = lf6, key = "B", nGroups = 2)
distractorAnalysis(items = test_items)
key_lf6 <- c("B")
key_mm14 <- c("C")
test_keys <- cbind(key_lf6, key_mm14)
distractorAnalysis(items = test_items, key = test_keys)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 1)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 2)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 1)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 3)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 4)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 5)
distractorAnalysis(items = test_items, key = test_keys, nGroups = 6)
lf1<- c("A", "B", "C", "A")
lf2<- c("A", "A", "A", "D")
lf6 <- c("A", "A", "B", "B")
mm14 <- c("A", "C", "C", "C")
key_lf1 <- c("A")
key_lf2 <- c("D")
key_lf6 <- c("B")
key_mm14 <- c("C")
test_items <- cbind(lf1, lf2, lf6, mm14)
test_keys <- cbind(key_lf1, key_lf2, key_lf6, key_mm14)
distractorAnalysis(items = test_items, key = test_keys)
data(CTTdata)
CTTdata
test_keys
test_items
CTTkey
data(CTTkey)
CTTkey
#test_keys <- cbind(key_lf1, key_lf2, key_lf6, key_mm14)
test_keys <- c("A", "D", "B", "C")
distractorAnalysis(items = test_items, key = test_keys)
test_keys
distractorAnalysis(CTTdata, CTTkey)
library(DescTools)
CronbachAlpha(test_data[,5:19])
alpha(test_data[,5:19])
item_facility <- colMeans(test_data[,5:19], na.rm=TRUE)
item_facility
test_data <- read.xls(file.choose())
test_data
?pearson
?cor
test_data
cor(test_data$avg_a, test_data$avg_f, method = c("pearson"))
cor.test(test_data$avg_a, test_data$avg_f, method = c("pearson"))
cor.test(test_data$avg_a, test_data$avg_f, method = c("spearman"))
dim(test_data)
test_data[,45:49]
install.packages("Hmisc")
library(Hmisc)
rcorr(as.matrix(test_data[,45:49]))
rcorr(as.matrix(test_data[,45:49]), type = c("spearman"))
rcorr(as.matrix(cbind(test_data$total_multiple_choice,
test_data$speaking_average)),
type = c("pearson"))
rcorr(as.matrix(cbind(test_data$total_multiple_choice,
test_data$speaking_average)),
type = c("spearman"))
rcorr(as.matrix(cbind(test_data$total_multiple_choice,
test_data$speaking_average)),
type = c("pearson"))
test_data
test_data <- read.xls(file.choose())
library(gdata)
library(Hmisc)
test_data <- read.xls(file.choose())
test_data
test_data <- read.xls(file.choose())
test_data
rcorr(as.matrix(cbind(test_data$ra1_avg_ro1_ro2,
test_data$ra2_avg_ro1_ro2)),
type = c("spearman"))
rcorr(as.matrix(cbind(test_data$ra1_ro1_avg,
test_data$ra1_ro2_avg,
test_data$ra2_ro1_avg,
test_data$ra2_ro2_avg)),
type = c("spearman"))
rcorr(as.matrix(cbind(test_data$ra1_ro1_avg,
test_data$ra1_ro2_avg)),
type = c("spearman"))
rcorr(as.matrix(cbind(test_data$ra2_ro1_avg,
test_data$ra2_ro2_avg)),
type = c("spearman"))
